import csv
import json
import secrets
from io import StringIO

from fastapi import APIRouter, UploadFile, Depends, HTTPException, status
from fastapi.params import Security
from fastapi.security import HTTPBasic, HTTPBasicCredentials
from sqlalchemy import delete, select
from sqlalchemy.orm import selectinload
from starlette.responses import JSONResponse, Response

from src.config import SUMM_MODELS_FILEPATHS, ADMIN_USERNAME, ADMIN_PASSWORD
from src.dependencies import SessionDep
from src.models import News
from src.parsers.parsers_selection import get_parsers_sites_urls, remove_parser, add_new_parser
from src.services.bg_service import get_last_parsing_time_from_config, start_bg_task
from src.services.summaries_service import create_summary_for_news
from src.summarizers.utils.model_selection import set_model_by_name, get_selected_model_name


def verify_admin(credentials: HTTPBasicCredentials = Security(HTTPBasic())):
    username_correct = secrets.compare_digest(credentials.username, ADMIN_USERNAME)
    password_correct = secrets.compare_digest(credentials.password, ADMIN_PASSWORD)

    if not (username_correct and password_correct):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="–ù–µ–≤–µ—Ä–Ω—ã–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ",
            headers={"WWW-Authenticate": "Basic"},
        )

    return credentials.username


admin_router = APIRouter(
    prefix="/admin",
    tags=["–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ü§ñ"],
    dependencies=[Depends(verify_admin)]
)


@admin_router.post("/summaries/", summary="–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—Ñ–µ—Ä–∞—Ç –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏")
async def generate_summary(news_url: str, session: SessionDep):
    await create_summary_for_news(session, news_url)
    return {"status": "OK", "message": "–†–µ—Ñ–µ—Ä–∞—Ç —Å–æ–∑–¥–∞–Ω"}


@admin_router.get("/models", summary="–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
def get_available_models():
    return {"available_models": list(SUMM_MODELS_FILEPATHS.keys())}


@admin_router.get("/models/selected", summary="–ü–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
def get_selected_model():
    name = get_selected_model_name()
    return {"selected_model": name}


@admin_router.post("/models/selected", summary="–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å")
def set_model(model_name: str):
    set_model_by_name(model_name)
    return {"status": "OK", "message": "–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"}


@admin_router.get("/parsers/sites", summary="–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å–∞–π—Ç–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
def get_all_parsers():
    return {"sites_urls": get_parsers_sites_urls()}


@admin_router.delete("/parsers/sites", summary="–£–¥–∞–ª–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Å–∞–π—Ç –∏–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞")
def delete_parser(site_url: str):
    remove_parser(site_url)
    return {"status": "OK", "message": "–ü–∞—Ä—Å–µ—Ä —É–¥–∞–ª–µ–Ω"}


@admin_router.post("/parsers", summary="–ó–∞–≥—Ä—É–∑–∏—Ç—å JSON-—Ñ–∞–π–ª —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –ø–∞—Ä—Å–µ—Ä–∞")
def load_parser(file: UploadFile):
    parser_config = json.load(file.file)
    add_new_parser(parser_config)
    return {"status": "OK", "message": "–ü–∞—Ä—Å–µ—Ä –¥–æ–±–∞–≤–ª–µ–Ω"}


@admin_router.get("/parsers/template", summary="–ü–æ–ª—É—á–∏—Ç—å —à–∞–±–ª–æ–Ω —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
def get_parser_template():
    return JSONResponse(
        {
            "site_url": "",
            "article_selector": "",
            "title_selector": "",
            "url_selector": "",
            "date_selector": "",
            "content_selector": "",
            "stop_words": []
        }
    )

@admin_router.get("/system", summary="–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ –∏ –∞–ª–≥–æ—Ä–∏—Ç–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
async def start_bg_task_():
    await start_bg_task()
    return {"status": "OK", "message": "–ê–ª–≥–æ—Ä–∏—Ç–º –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–ø—É—â–µ–Ω"}


@admin_router.get("/system/timestamp", summary="–ü–æ–ª—É—á–∏—Ç—å –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞")
async def get_last_parsing_time():
    last_time = get_last_parsing_time_from_config()
    return {"last_parsing_time": last_time}


@admin_router.delete("/cluster/{cluster_n}", summary="–£–¥–∞–ª–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä")
async def delete_cluster(cluster_n: int, session: SessionDep):
    await session.execute(
        delete(News)
        .where(News.cluster_n == cluster_n)
    )
    await session.commit()
    return {"status": "OK", "message": "–ö–ª–∞—Å—Ç–µ—Ä –±—ã–ª —É–¥–∞–ª–µ–Ω"}


@admin_router.get("/news/export", summary="–°–∫–∞—á–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É .csv", response_class=Response)
async def export_news_with_summaries(session: SessionDep):
        query = (
            select(News)
            .options(selectinload(News.summary))
            .where(News.summary.any())

        )
        result = await session.execute(query)
        news_items = result.scalars().all()

        if not news_items:
            raise HTTPException(status_code=404, detail="–ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Ä–µ—Ñ–µ—Ä–∞—Ç–∞–º–∏")

        output = StringIO()
        writer = csv.writer(output, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)

        headers = [
            "url", "title", "date", "content",
            "summary_content", "positive_rates", "negative_rates"
        ]
        writer.writerow(headers)

        for news in news_items:
            if not news.summary:
                continue

            summary = news.summary[0]
            writer.writerow([
                news.url,
                news.title,
                news.published_at.isoformat(),
                news.content,
                summary.content,
                summary.positive_rates,
                summary.negative_rates
            ])

        output.seek(0)
        return Response(
            content=output.getvalue(),
            media_type="text/csv",
            headers={
                "Content-Disposition": "attachment; filename=news_with_summaries.csv",
                "Content-Type": "text/csv; charset=utf-8"
            }
        )